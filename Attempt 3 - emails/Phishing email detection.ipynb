{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23afdfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6c7c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_data = pd.read_csv(\"Email-trainingdata.csv\", header=None)\n",
    "pd.isnull(train_data).values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d411c567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: what up , , your cam babe what are yo...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: want to make more money ? order confi...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: food for thoughts [ join now - take a...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: your pharmacy ta would you want cheap...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: bigger breast just from a pill image ...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1     2\n",
       "0  Subject: what up , , your cam babe what are yo...  phishing  spam\n",
       "1  Subject: want to make more money ? order confi...  phishing  spam\n",
       "2  Subject: food for thoughts [ join now - take a...  phishing  spam\n",
       "3  Subject: your pharmacy ta would you want cheap...  phishing  spam\n",
       "4  Subject: bigger breast just from a pill image ...  phishing  spam"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1683ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = ['prompt', 'category', 'completion']\n",
    "train_data.drop('category', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc3664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17830"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.prompt.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27bb6ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.completion.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c5dc741",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_json(\"train_data.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec01054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 17830 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- All prompts start with prefix `Subject: `\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified files to `train_data_prepared_train.jsonl` and `train_data_prepared_valid.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"train_data_prepared_train.jsonl\" -v \"train_data_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" spam\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"am\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 7.17 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f train_data.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5a6104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file from train_data_prepared_train.jsonl: file-QYoVNSIEu9ThXI9N8PkH5p4t\n",
      "Uploaded file from train_data_prepared_valid.jsonl: file-CQnFA9gQGLnT19CkLIIVKEe0\n",
      "Created fine-tune: ft-wCf4SfAovL1Fp8I0W0xCKegj\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-02-22 01:15:21] Created fine-tune: ft-wCf4SfAovL1Fp8I0W0xCKegj\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-wCf4SfAovL1Fp8I0W0xCKegj\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Upload progress:   0%|          | 0.00/8.47M [00:00<?, ?it/s]\n",
      "Upload progress: 100%|##########| 8.47M/8.47M [00:00<00:00, 2.12Git/s]\n",
      "\n",
      "Upload progress:   0%|          | 0.00/496k [00:00<?, ?it/s]\n",
      "Upload progress: 100%|##########| 496k/496k [00:00<00:00, 244Mit/s]\n"
     ]
    }
   ],
   "source": [
    "!openai --api-key \"xx\" api fine_tunes.create -t \"train_data_prepared_train.jsonl\" -v \"train_data_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" spam\" -m ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8ecc620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6mZogRSqbCZNteDNNnxCAtmNwNFU8 at 0x1df42160b30> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"  please don ' t hesitate to e - mail me at zimin @\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1677035442,\n",
       "  \"id\": \"cmpl-6mZogRSqbCZNteDNNnxCAtmNwNFU8\",\n",
       "  \"model\": \"ada:ft-personal-2023-02-22-02-07-41\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 1053,\n",
       "    \"total_tokens\": 1069\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key =\"xx\"\n",
    "openai.Completion.create(\n",
    "    model=\"ada:ft-personal-2023-02-22-02-07-41\",\n",
    "    prompt=\"Subject: re : storage model : simple issues  brad ,  here are my thoughts on your concerns .  * you needs curve inputs . this is an it job . i can help you for the curves  before the system is properly set up .  * intrinsic value vs time value :  the intrinsic value depends on how you allocate the volumes . if you have a  rough idea about the allocation as  you did in the spreadsheet , we can calucate the intrinsic value within the  model . the difference between the  total and the intrinsic will be the ( option ) time value . however , by  pre - allocating volumes , you killed some options .  in the storage model , volumes are allocated dynamically , therefore it is  hard to distinguish the intrinsic vs . time value .  * factor of loading : factor of loadings are used to give historical  correlation matrix . the three factors correspond to  paralle shift , slopping and curveture . the covariance matrix in the model  is expressed in the form  covar = row ( vol _ { i } ) * ( correl ( i , j ) ) * colum ( vol _ { j } ) where vols are  the implied volatilities from the vol curve .  ( correl ( i , j ) ) = l * l ' + residue ( small )  where l is the factor of loading matrix . so in a simple words , the factor of  loadings ( say , 60 x 3 ) are a simplier way for us to  remember the historical correlation matrix ( say , 60 x 60 ) .  let me know if i can offer further help .  zimin  brad horn 02 / 15 / 2000 07 : 15 am  to : zimin lu / hou / ect @ ect  cc : sandra henderson / hou / ect @ ect  subject : storage model : simple issues  zimin :  thanks for your time with the revised storage valuation . your right to  point out the similarity to market bids . here are some basic questions tied  to implementation and calibration :  model infrastructure / it support : i obviously need to re - build my link to the  forward curves as the model is not working in my new location . short - term  ( aprox 1 month ) , i ' d like to establish a link to the ena database egsprod 32  in order to fetch the long - dated price and volatility curves . my link to ena  forward curves would then be quickly severed in favor of the curves generated  by the new bridgeline entity ( database name and data structure yet to be  defined ) . however , its not clear to me what is required in this two stage  process to support your model . any definition of model input or minimum  support requirements you provide is appreciated . i ' ll then work with sandra  henderson , an enron employee providing our it support , to ensure the model  continues to work regardless any downstream system changes that may take  place as we build and establish our separate trading systems or databases .  meanwhile , is there anything you think you can do to ensure im up and running  quickly ?  sandra : linking excel spreadsheets to bridgeline forward curves will be key  to all our pricing projects , not just the storage model supplied by research .  intrinsic vs extrinsic value : it would be helpful to decompose the model ' s  calculated storage price and to distinguish intrinsic vs extrinsic ( time or  option ) value . i could easily link a new spreadsheet tab to your model  inputs and to calculate the intrinsic value , and then through a simple  difference i could determine the extrinsic value . ive included a simple  spreadsheet calculation for the intrinsic value for review . i wanted to  share this with you to ask the following :  does the nature of the model define intrinsic and extrinsic value differently  than the simple difference proposed ?  do you think it would make sense to do the simple value decomposition in the  backcode c - code via . dll in order to ensure run - time is faster ?  my goal here is straightforward : a ) to better understand the model and its  sensitivities . ; and b ) to determine if and when the option approach is  associating significant value above and beyond the simple present value of  the time spreads .  factor loadings : what are some of the thoughts or insights you can offer with  regards to factor loadings and how i should interpret the graph of the 3  factors calculated ? factor loadings have always been a mystery to me . for  example , what problems should i be looking for as a warning against  mispricing ? what , if anything , is implied about 1 day price change or  expected curve re - shapings ( after all , curve - reshapings are key to storage  valuation ! ! ! ) ?  calibration : we are preparing a simple summary of descriptive statistics  which should allow me to refine some of the model inputs . i ' ll share the  data when we are and model results once im up and running .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1de055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
